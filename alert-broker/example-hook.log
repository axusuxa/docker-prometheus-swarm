2017/08/18 14:06:38 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.160:18080",
        "job": "cadvisor",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T11:21:38.006+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.164:18080",
        "job": "cadvisor",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T11:18:08.006+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.169.66:18080",
        "job": "cadvisor",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:01:08.006+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.163:18080",
        "job": "cadvisor",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:06:08.006+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "monitoring_service_down"
  },
  "commonLabels": {
    "alertname": "monitoring_service_down",
    "env": "prod",
    "job": "cadvisor",
    "monitor": "prometheus-swarm"
  },
  "commonAnnotations": {
    "description": "The monitoring service 'cadvisor' is down.",
    "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"monitoring_service_down\"}"
}

2017/08/18 14:11:38 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.160:18080",
        "job": "cadvisor",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T11:21:38.006+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.164:18080",
        "job": "cadvisor",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T11:18:08.006+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "resolved",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.169.66:18080",
        "job": "cadvisor",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:01:08.006+07:00",
      "endsAt": "2017-08-18T14:08:38.006+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "resolved",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.163:18080",
        "job": "cadvisor",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:06:08.006+07:00",
      "endsAt": "2017-08-18T14:10:08.006+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "monitoring_service_down"
  },
  "commonLabels": {
    "alertname": "monitoring_service_down",
    "env": "prod",
    "job": "cadvisor",
    "monitor": "prometheus-swarm"
  },
  "commonAnnotations": {
    "description": "The monitoring service 'cadvisor' is down.",
    "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"monitoring_service_down\"}"
}

2017/08/18 14:16:38 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "high_la_usage_on_node",
        "env": "prod",
        "instance": "10.77.170.160:9100",
        "job": "node-exporter",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "10.77.170.160:9100 has a high load average. Load Average 5m is 9.4.",
        "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.160:9100'"
      },
      "startsAt": "2017-08-18T11:06:37.803+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=node_load5+%3E+5\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "high_la_usage_on_node",
        "env": "prod",
        "instance": "10.77.170.164:9100",
        "job": "node-exporter",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "10.77.170.164:9100 has a high load average. Load Average 5m is 8.36.",
        "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.164:9100'"
      },
      "startsAt": "2017-08-18T11:06:37.803+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=node_load5+%3E+5\u0026g0.tab=0"
    },
    {
      "status": "resolved",
      "labels": {
        "alertname": "high_la_usage_on_node",
        "env": "prod",
        "instance": "10.77.169.66:9100",
        "job": "node-exporter",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "10.77.169.66:9100 has a high load average. Load Average 5m is 5.14.",
        "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.169.66:9100'"
      },
      "startsAt": "2017-08-18T14:04:08.006+07:00",
      "endsAt": "2017-08-18T14:13:08.006+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=node_load5+%3E+5\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "high_la_usage_on_node"
  },
  "commonLabels": {
    "alertname": "high_la_usage_on_node",
    "env": "prod",
    "job": "node-exporter",
    "monitor": "prometheus-swarm"
  },
  "commonAnnotations": {},
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"high_la_usage_on_node\"}"
}

2017/08/18 14:21:38 {
  "receiver": "webhook",
  "status": "resolved",
  "alerts": [
    {
      "status": "resolved",
      "labels": {
        "alertname": "high_la_usage_on_node",
        "env": "prod",
        "instance": "10.77.170.160:9100",
        "job": "node-exporter",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "10.77.170.160:9100 has a high load average. Load Average 5m is 9.4.",
        "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.160:9100'"
      },
      "startsAt": "2017-08-18T11:06:37.803+07:00",
      "endsAt": "2017-08-18T14:21:38.015336637+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=node_load5+%3E+5\u0026g0.tab=0"
    },
    {
      "status": "resolved",
      "labels": {
        "alertname": "high_la_usage_on_node",
        "env": "prod",
        "instance": "10.77.170.164:9100",
        "job": "node-exporter",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "10.77.170.164:9100 has a high load average. Load Average 5m is 8.36.",
        "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.164:9100'"
      },
      "startsAt": "2017-08-18T11:06:37.803+07:00",
      "endsAt": "2017-08-18T14:21:38.015336637+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=node_load5+%3E+5\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "high_la_usage_on_node"
  },
  "commonLabels": {
    "alertname": "high_la_usage_on_node",
    "env": "prod",
    "job": "node-exporter",
    "monitor": "prometheus-swarm"
  },
  "commonAnnotations": {},
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"high_la_usage_on_node\"}"
}

2017/08/18 14:21:38 {
  "receiver": "webhook",
  "status": "resolved",
  "alerts": [
    {
      "status": "resolved",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.160:18080",
        "job": "cadvisor",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T11:21:38.006+07:00",
      "endsAt": "2017-08-18T14:21:38.017272476+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "resolved",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.164:18080",
        "job": "cadvisor",
        "monitor": "prometheus-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T11:18:08.006+07:00",
      "endsAt": "2017-08-18T14:21:38.017272476+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "monitoring_service_down"
  },
  "commonLabels": {
    "alertname": "monitoring_service_down",
    "env": "prod",
    "job": "cadvisor",
    "monitor": "prometheus-swarm"
  },
  "commonAnnotations": {
    "description": "The monitoring service 'cadvisor' is down.",
    "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"monitoring_service_down\"}"
}

2017/08/18 14:23:07 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.164:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.160:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "monitoring_service_down"
  },
  "commonLabels": {
    "alertname": "monitoring_service_down",
    "env": "prod",
    "job": "cadvisor",
    "monitor": "docker-swarm"
  },
  "commonAnnotations": {
    "description": "The monitoring service 'cadvisor' is down.",
    "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"monitoring_service_down\"}"
}

2017/08/18 14:23:07 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "high_la_usage_on_node",
        "env": "prod",
        "instance": "10.77.170.160:9100",
        "job": "node-exporter",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "10.77.170.160:9100 has a high load average. Load Average 5m is 9.18.",
        "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.160:9100'"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=node_load5+%3E+8\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "high_la_usage_on_node"
  },
  "commonLabels": {
    "alertname": "high_la_usage_on_node",
    "env": "prod",
    "instance": "10.77.170.160:9100",
    "job": "node-exporter",
    "monitor": "docker-swarm"
  },
  "commonAnnotations": {
    "description": "10.77.170.160:9100 has a high load average. Load Average 5m is 9.18.",
    "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.160:9100'"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"high_la_usage_on_node\"}"
}

2017/08/18 14:28:07 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "resolved",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.169.66:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:23:37.963+07:00",
      "endsAt": "2017-08-18T14:26:07.963+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.164:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.160:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "monitoring_service_down"
  },
  "commonLabels": {
    "alertname": "monitoring_service_down",
    "env": "prod",
    "job": "cadvisor",
    "monitor": "docker-swarm"
  },
  "commonAnnotations": {
    "description": "The monitoring service 'cadvisor' is down.",
    "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"monitoring_service_down\"}"
}

2017/08/18 14:33:07 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.160:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.169.66:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:31:37.963+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.164:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "monitoring_service_down"
  },
  "commonLabels": {
    "alertname": "monitoring_service_down",
    "env": "prod",
    "job": "cadvisor",
    "monitor": "docker-swarm"
  },
  "commonAnnotations": {
    "description": "The monitoring service 'cadvisor' is down.",
    "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"monitoring_service_down\"}"
}

2017/08/18 14:38:07 {
  "receiver": "webhook",
  "status": "resolved",
  "alerts": [
    {
      "status": "resolved",
      "labels": {
        "alertname": "high_la_usage_on_node",
        "env": "prod",
        "instance": "10.77.170.160:9100",
        "job": "node-exporter",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "10.77.170.160:9100 has a high load average. Load Average 5m is 8.14.",
        "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.160:9100'"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "2017-08-18T14:35:07.963+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=node_load5+%3E+8\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "high_la_usage_on_node"
  },
  "commonLabels": {
    "alertname": "high_la_usage_on_node",
    "env": "prod",
    "instance": "10.77.170.160:9100",
    "job": "node-exporter",
    "monitor": "docker-swarm"
  },
  "commonAnnotations": {
    "description": "10.77.170.160:9100 has a high load average. Load Average 5m is 8.14.",
    "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.160:9100'"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"high_la_usage_on_node\"}"
}

2017/08/18 14:38:07 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "resolved",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.163:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:33:37.963+07:00",
      "endsAt": "2017-08-18T14:36:07.963+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.164:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.160:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "resolved",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.169.66:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:31:37.963+07:00",
      "endsAt": "2017-08-18T14:34:07.963+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "monitoring_service_down"
  },
  "commonLabels": {
    "alertname": "monitoring_service_down",
    "env": "prod",
    "job": "cadvisor",
    "monitor": "docker-swarm"
  },
  "commonAnnotations": {
    "description": "The monitoring service 'cadvisor' is down.",
    "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"monitoring_service_down\"}"
}

2017/08/18 14:40:07 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "high_la_usage_on_node",
        "env": "prod",
        "instance": "10.77.170.164:9100",
        "job": "node-exporter",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "10.77.170.164:9100 has a high load average. Load Average 5m is 8.92.",
        "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.164:9100'"
      },
      "startsAt": "2017-08-18T14:39:37.963+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=node_load5+%3E+8\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "high_la_usage_on_node"
  },
  "commonLabels": {
    "alertname": "high_la_usage_on_node",
    "env": "prod",
    "instance": "10.77.170.164:9100",
    "job": "node-exporter",
    "monitor": "docker-swarm"
  },
  "commonAnnotations": {
    "description": "10.77.170.164:9100 has a high load average. Load Average 5m is 8.92.",
    "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.164:9100'"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"high_la_usage_on_node\"}"
}

2017/08/18 14:43:07 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.160:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.163:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:41:37.963+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.164:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "monitoring_service_down"
  },
  "commonLabels": {
    "alertname": "monitoring_service_down",
    "env": "prod",
    "job": "cadvisor",
    "monitor": "docker-swarm"
  },
  "commonAnnotations": {
    "description": "The monitoring service 'cadvisor' is down.",
    "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"monitoring_service_down\"}"
}

2017/08/18 14:45:07 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "high_la_usage_on_node",
        "env": "prod",
        "instance": "10.77.170.164:9100",
        "job": "node-exporter",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "10.77.170.164:9100 has a high load average. Load Average 5m is 9.11.",
        "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.164:9100'"
      },
      "startsAt": "2017-08-18T14:39:37.963+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=node_load5+%3E+8\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "high_la_usage_on_node",
        "env": "prod",
        "instance": "10.77.170.160:9100",
        "job": "node-exporter",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "10.77.170.160:9100 has a high load average. Load Average 5m is 9.39.",
        "summary": "HIGH LOAD AVERAGE WARNING ON '10.77.170.160:9100'"
      },
      "startsAt": "2017-08-18T14:40:37.963+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=node_load5+%3E+8\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "high_la_usage_on_node"
  },
  "commonLabels": {
    "alertname": "high_la_usage_on_node",
    "env": "prod",
    "job": "node-exporter",
    "monitor": "docker-swarm"
  },
  "commonAnnotations": {},
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"high_la_usage_on_node\"}"
}

2017/08/18 14:48:07 {
  "receiver": "webhook",
  "status": "firing",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.160:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "resolved",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.163:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:41:37.963+07:00",
      "endsAt": "2017-08-18T14:45:07.963+07:00",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    },
    {
      "status": "firing",
      "labels": {
        "alertname": "monitoring_service_down",
        "env": "prod",
        "instance": "10.77.170.164:18080",
        "job": "cadvisor",
        "monitor": "docker-swarm"
      },
      "annotations": {
        "description": "The monitoring service 'cadvisor' is down.",
        "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
      },
      "startsAt": "2017-08-18T14:22:37.804+07:00",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://i-grafana1:9090/graph?g0.expr=up+%3D%3D+0\u0026g0.tab=0"
    }
  ],
  "groupLabels": {
    "alertname": "monitoring_service_down"
  },
  "commonLabels": {
    "alertname": "monitoring_service_down",
    "env": "prod",
    "job": "cadvisor",
    "monitor": "docker-swarm"
  },
  "commonAnnotations": {
    "description": "The monitoring service 'cadvisor' is down.",
    "summary": "MONITORING SERVICE DOWN WARNING: NODE ''"
  },
  "externalURL": "http://i-grafana1:9093",
  "version": "4",
  "groupKey": "{}/{env=~\"^(?:^(.*)$)$\"}:{alertname=\"monitoring_service_down\"}"
}